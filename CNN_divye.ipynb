{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9456382,"sourceType":"datasetVersion","datasetId":5748526},{"sourceId":9456445,"sourceType":"datasetVersion","datasetId":5748578},{"sourceId":9460247,"sourceType":"datasetVersion","datasetId":5751324},{"sourceId":9460259,"sourceType":"datasetVersion","datasetId":5751334}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\n# Define directories for train and test datasets\ntrain_dir = r'/kaggle/input/recycle-with-split/recycle_split/train'\ntest_dir = r'/kaggle/input/recycle-with-split/recycle_split/test'\n\n# Image size and batch size\nIMG_HEIGHT = 150\nIMG_WIDTH = 150\nBATCH_SIZE = 64\n\n# Step 1: Data Augmentation and Preprocessing\ntrain_image_generator = ImageDataGenerator(\n    rescale=1.0/255.0,  # Normalize pixel values between 0 and 1\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntest_image_generator = ImageDataGenerator(rescale=1.0/255.0)\n\ntrain_data_gen = train_image_generator.flow_from_directory(\n    batch_size=BATCH_SIZE,\n    directory=train_dir,\n    shuffle=True,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    class_mode='categorical'  # For multi-class classification\n)\n\ntest_data_gen = test_image_generator.flow_from_directory(\n    batch_size=BATCH_SIZE,\n    directory=test_dir,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    class_mode='categorical'\n)\n\n# Step 2: Build CNN Model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(4, activation='softmax')  # 4 classes: glass, paper, plastic, metal\n])\n\n# Step 3: Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Step 4: Train the model\nEPOCHS = 20\nhistory = model.fit(\n    train_data_gen,\n    epochs=EPOCHS,\n    validation_data=test_data_gen,\n    verbose=1\n)\n\n# Step 5: Evaluate the model\ntest_loss, test_acc = model.evaluate(test_data_gen)\nprint(f\"Test accuracy: {test_acc}\")\n\n# Step 6: Predict on new images\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n# Load a new image for prediction\nimg_path = '/kaggle/input/plastic/plastic_0039.jpg'\nimg = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\nimg_array = image.img_to_array(img) / 255.0  # Normalize the image\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Make a prediction\nprediction = model.predict(img_array)\nclass_names = list(train_data_gen.class_indices.keys())\npredicted_class = class_names[np.argmax(prediction)]\nprint(f\"Predicted class: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T12:50:02.243363Z","iopub.execute_input":"2024-09-23T12:50:02.244155Z","iopub.status.idle":"2024-09-23T14:46:34.394356Z","shell.execute_reply.started":"2024-09-23T12:50:02.244098Z","shell.execute_reply":"2024-09-23T14:46:34.393129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 6: Save the model\nmodel_save_path = r'/kaggle/working/waste_classification_model.h5'\nmodel.save(model_save_path)\nprint(f\"Model saved at: {model_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:46:34.396867Z","iopub.execute_input":"2024-09-23T14:46:34.397736Z","iopub.status.idle":"2024-09-23T14:46:34.717935Z","shell.execute_reply.started":"2024-09-23T14:46:34.397679Z","shell.execute_reply":"2024-09-23T14:46:34.716728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load a new image for prediction\nimg_path = '/kaggle/input/papers2/paper_0177.jpg'\nimg = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\nimg_array = image.img_to_array(img) / 255.0  # Normalize the image\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Make a prediction\nprediction = model.predict(img_array)\nclass_names = list(train_data_gen.class_indices.keys())\npredicted_class = class_names[np.argmax(prediction)]\nprint(f\"Predicted class: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:46:34.719365Z","iopub.execute_input":"2024-09-23T14:46:34.719825Z","iopub.status.idle":"2024-09-23T14:46:34.820733Z","shell.execute_reply.started":"2024-09-23T14:46:34.719782Z","shell.execute_reply":"2024-09-23T14:46:34.819218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load a new image for prediction\nimg_path = '/kaggle/input/recycle-with-split/recycle_split/test/glass/glass_0076.jpg'\nimg = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\nimg_array = image.img_to_array(img) / 255.0  # Normalize the image\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Make a prediction\nprediction = model.predict(img_array)\nclass_names = list(train_data_gen.class_indices.keys())\npredicted_class = class_names[np.argmax(prediction)]\nprint(f\"Predicted class: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:46:34.823768Z","iopub.execute_input":"2024-09-23T14:46:34.824761Z","iopub.status.idle":"2024-09-23T14:46:34.919642Z","shell.execute_reply.started":"2024-09-23T14:46:34.824702Z","shell.execute_reply":"2024-09-23T14:46:34.918467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load a new image for prediction\nimg_path = '/kaggle/input/recycle-with-split/recycle_split/test/metal/metal_0072.jpg'\nimg = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\nimg_array = image.img_to_array(img) / 255.0  # Normalize the image\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Make a prediction\nprediction = model.predict(img_array)\nclass_names = list(train_data_gen.class_indices.keys())\npredicted_class = class_names[np.argmax(prediction)]\nprint(f\"Predicted class: {predicted_class}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T14:46:34.920895Z","iopub.execute_input":"2024-09-23T14:46:34.921287Z","iopub.status.idle":"2024-09-23T14:46:35.019265Z","shell.execute_reply.started":"2024-09-23T14:46:34.921250Z","shell.execute_reply":"2024-09-23T14:46:35.018129Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
