{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9456382,"sourceType":"datasetVersion","datasetId":5748526}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-10-27T10:12:12.510895Z","iopub.execute_input":"2024-10-27T10:12:12.511186Z","iopub.status.idle":"2024-10-27T10:12:16.926409Z","shell.execute_reply.started":"2024-10-27T10:12:12.511153Z","shell.execute_reply":"2024-10-27T10:12:16.925468Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Data transformations with Mixup (augmentation) and normalization\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntransform_val = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load dataset\ntrain_dataset = datasets.ImageFolder(root=\"/kaggle/input/recycle-with-split/recycle_split/train\", transform=transform_train)\nval_dataset = datasets.ImageFolder(root=\"/kaggle/input/recycle-with-split/recycle_split/test\", transform=transform_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T10:34:23.440555Z","iopub.execute_input":"2024-10-27T10:34:23.441446Z","iopub.status.idle":"2024-10-27T10:34:35.757099Z","shell.execute_reply.started":"2024-10-27T10:34:23.441405Z","shell.execute_reply":"2024-10-27T10:34:35.756226Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# Load the MobileNetV2 model pre-trained on ImageNet\nnum_classes = 4 \nmodel = models.mobilenet_v2(pretrained=True)\nmodel.classifier[1] = nn.Linear(model.last_channel, num_classes)  # Adjust for number of classes\n\nmodel = model.to(device)\n\n# Label smoothing criterion\nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, classes, smoothing=0.1):\n        super(LabelSmoothingLoss, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.cls = classes\n        self.log_softmax = nn.LogSoftmax(dim=-1)\n\n    def forward(self, x, target):\n        with torch.no_grad():\n            true_dist = torch.zeros_like(x)\n            true_dist.fill_(self.smoothing / (self.cls - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * self.log_softmax(x), dim=-1))\n\nnum_classes = 4  # Update with your number of classes\ncriterion = LabelSmoothingLoss(classes=num_classes, smoothing=0.1)\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T10:35:49.135743Z","iopub.execute_input":"2024-10-27T10:35:49.136623Z","iopub.status.idle":"2024-10-27T10:35:49.288942Z","shell.execute_reply.started":"2024-10-27T10:35:49.136562Z","shell.execute_reply":"2024-10-27T10:35:49.287583Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Training the model\nnum_epochs = 30\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        _, predicted = outputs.max(1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\n    epoch_loss = running_loss / total\n    epoch_acc = 100 * correct / total\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n\n# Validation loop\nmodel.eval()\nval_loss = 0.0\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        val_loss += loss.item() * images.size(0)\n        _, predicted = outputs.max(1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\nval_loss /= total\nval_accuracy = 100 * correct / total\nprint(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-27T10:48:46.124801Z","iopub.execute_input":"2024-10-27T10:48:46.125603Z","iopub.status.idle":"2024-10-27T11:20:55.205152Z","shell.execute_reply.started":"2024-10-27T10:48:46.125562Z","shell.execute_reply":"2024-10-27T11:20:55.204171Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch [1/30], Loss: 0.7684, Accuracy: 81.53%\nEpoch [2/30], Loss: 0.8053, Accuracy: 79.12%\nEpoch [3/30], Loss: 0.7748, Accuracy: 80.81%\nEpoch [4/30], Loss: 0.7594, Accuracy: 81.77%\nEpoch [5/30], Loss: 0.7508, Accuracy: 82.50%\nEpoch [6/30], Loss: 0.7493, Accuracy: 82.79%\nEpoch [7/30], Loss: 0.7340, Accuracy: 83.56%\nEpoch [8/30], Loss: 0.7345, Accuracy: 83.67%\nEpoch [9/30], Loss: 0.7665, Accuracy: 81.61%\nEpoch [10/30], Loss: 0.7408, Accuracy: 82.99%\nEpoch [11/30], Loss: 0.7322, Accuracy: 83.44%\nEpoch [12/30], Loss: 0.7248, Accuracy: 83.94%\nEpoch [13/30], Loss: 0.7261, Accuracy: 83.93%\nEpoch [14/30], Loss: 0.7169, Accuracy: 84.37%\nEpoch [15/30], Loss: 0.7142, Accuracy: 84.74%\nEpoch [16/30], Loss: 0.7066, Accuracy: 85.09%\nEpoch [17/30], Loss: 0.7084, Accuracy: 85.20%\nEpoch [18/30], Loss: 0.6935, Accuracy: 85.58%\nEpoch [19/30], Loss: 0.6954, Accuracy: 85.60%\nEpoch [20/30], Loss: 0.7217, Accuracy: 83.93%\nEpoch [21/30], Loss: 0.7306, Accuracy: 83.51%\nEpoch [22/30], Loss: 0.6972, Accuracy: 85.46%\nEpoch [23/30], Loss: 0.6813, Accuracy: 86.66%\nEpoch [24/30], Loss: 0.6850, Accuracy: 86.34%\nEpoch [25/30], Loss: 0.6815, Accuracy: 86.38%\nEpoch [26/30], Loss: 0.6763, Accuracy: 86.87%\nEpoch [27/30], Loss: 0.6727, Accuracy: 87.20%\nEpoch [28/30], Loss: 0.6765, Accuracy: 86.79%\nEpoch [29/30], Loss: 0.6677, Accuracy: 86.59%\nEpoch [30/30], Loss: 0.6645, Accuracy: 87.22%\nValidation Loss: 0.6920, Validation Accuracy: 86.26%\n","output_type":"stream"}]}]}